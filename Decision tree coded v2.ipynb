{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "from numpy import log, dot, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titantic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = pd.read_csv('titanic.csv',nrows=200)\n",
    "X = Xx[['Pclass','Sex','Siblings/Spouses Aboard','Parents/Children Aboard','Survived']]\n",
    "X = pd.get_dummies(X)\n",
    "X['target'] = X['Survived']\n",
    "X = X.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset columns\n",
    "header = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for user generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_data(hm_features,obs):\n",
    "\n",
    "        X = np.ones((obs))\n",
    "\n",
    "        for i in range(hm_features):\n",
    "            xs = np.random.rand(obs)*100\n",
    "            X = np.append(X,xs)\n",
    "\n",
    "        X = np.reshape(X, (-1,obs)).transpose()\n",
    "        ys = np.random.randint(0,2,size=obs) # 2 high as it's exclusive\n",
    "\n",
    "        return X,ys    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,t = create_random_data(4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\n",
    "    Note - this function expect last column as target variable\n",
    "    Output - {0:12,1:43} 12 0's and 43 1's\n",
    "    \"\"\"\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        \n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric_(val):\n",
    "    '''\n",
    "    check if given value is a integer or float\n",
    "    '''\n",
    "    return isinstance(val,int) or isinstance(val,float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demo\n",
    "is_numeric_(2)\n",
    "#True\n",
    "\n",
    "is_numeric_(\"red\")\n",
    "#False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st step - Create a question to ask based on feature and threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question():\n",
    "    '''\n",
    "    This is the first step in building the decision tree\n",
    "    Build a question i.e. Given a column and value, what would be\n",
    "    the question?\n",
    "    \n",
    "    question(1,3)\n",
    "    >>is Siblings/Spouses Aboard >= 3 \n",
    "    \n",
    "    question(2,0)\n",
    "    >>is Parents/Children Aboard >= 0 \n",
    "    \n",
    "    '''\n",
    "    def __init__(self,col,val):\n",
    "        self.col = col\n",
    "        self.val = val\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if is_numeric_(self.val):\n",
    "            return  \"is %s >= %s \" % (header[self.col],self.val)\n",
    "        else: return \"is %s == %s \" % (header[self.col],self.val)\n",
    "    \n",
    "    def match(self,df):\n",
    "        '''\n",
    "        compare feature value in df to threshold value we have created \n",
    "        '''\n",
    "        v = df[self.col]\n",
    "        if is_numeric_(v):\n",
    "            return v >= self.val\n",
    "        else:\n",
    "            return v == self.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Partition dataset based on question & output 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_my_data(df,ask_question):\n",
    "    '''\n",
    "    2nd part is partition dataset based on question\n",
    "    \n",
    "    partition_my_data(df,question(column = 2,value = 0))\n",
    "    >> create two df i.e. true rows where question conditon match\n",
    "    and false rows where question doesn't match\n",
    "    \n",
    "    len(tr), len(fr)\n",
    "    >>(148,52)\n",
    "    \n",
    "    '''\n",
    "    true_rows, false_rows = [] , []\n",
    "    for r in df:\n",
    "        if ask_question.match(r):\n",
    "            true_rows.append(r)\n",
    "        else:\n",
    "            false_rows.append(r)\n",
    "            \n",
    "    return true_rows,false_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd part - Calculate Information gain for all features & threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_gini(df):\n",
    "    '''\n",
    "    Gini formula = 1 - (prob_of_1)^2 - (prob_of_0)^2\n",
    "    \n",
    "    Example\n",
    "    cal_gini(X) #parent node gini\n",
    "    >> 0.545\n",
    "    \n",
    "    '''\n",
    "    impurity = 1\n",
    "    counts = class_counts(df) # calculate y distribution of df\n",
    "    \n",
    "    for c in counts:\n",
    "        prob_of_c = counts[c] / float(len(df))\n",
    "        impurity -= (prob_of_c)**2\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left_rows,right_rows,current_info):\n",
    "    '''\n",
    "    Information gain = current_information_gain [parent node] - left node - right node\n",
    "    Information gain = current_info - p(gini(left)) - (1-p)gini(right)\n",
    "    where p is no of rows in left/ total rows (left+right)\n",
    "    \n",
    "    Example\n",
    "    info_gain(false_rows, true_rows, current_gini)\n",
    "    >> 0.43\n",
    "    '''\n",
    "    p = float( len(left_rows)/ (len(left_rows)+len(right_rows)))\n",
    "    \n",
    "    return current_info - (p * cal_gini(left_rows)) - ((1-p) * cal_gini(right_rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th part - Find best feature and threshold using information gain\n",
    "### Note - 4th part reach out to part 1-3 so everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(x):\n",
    "    '''\n",
    "    finding the best question to ask i.e. best feature and best threshold\n",
    "    calculate the IV\n",
    "    \n",
    "    Example\n",
    "    \n",
    "    best_split(X.to_numpy())\n",
    "    >>(0.15340430723878157, is Sex_female == 0 )\n",
    "    '''\n",
    "    #Function output values best gain and best question\n",
    "    best_gain = 0 #to track the IV values\n",
    "    best_question = None #best question based on feature and threshold\n",
    "    \n",
    "    \n",
    "    #Parent node gini value\n",
    "    currrent_uncertainity = cal_gini(x)\n",
    "    n_feature = len(x[0]) - 1 # -1 for target feature\n",
    "    \n",
    "    for col in range(n_feature): # for each feature\n",
    "        u_val = set([xi[col] for xi in x]) # unique values of features\n",
    "        \n",
    "        for u_v in u_val:\n",
    "            \n",
    "            #1st part\n",
    "            my_question = question(col,u_v) #create condition\n",
    "            \n",
    "            #2nd part\n",
    "            true_rows, false_rows = partition_my_data(x,my_question) #split data based on question\n",
    "            \n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            \n",
    "            #3rd part\n",
    "            my_gain = info_gain(true_rows,false_rows,currrent_uncertainity) # find IV\n",
    "            \n",
    "            #to track best gain value and feature\n",
    "            if my_gain > best_gain:\n",
    "                best_gain, best_question = my_gain, my_question\n",
    "                \n",
    "    return best_gain,best_question    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th part - Create a decision node and leaf to hold parent and child nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leaf():\n",
    "    '''\n",
    "    leaf node hold the original target value distribution\n",
    "    {0:12,1:50} Means there are 12 0's and 50 1's in training data\n",
    "    \n",
    "    >> This will be the leaf node which will hold distribution of target variable based on all\n",
    "    condition\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,rows):\n",
    "        self.predictions = class_counts(rows)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    question -> from 1st part\n",
    "    true branch and false branch --> from 2nd part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6th part - train decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(x):\n",
    "    '''\n",
    "    rules of recursion: 1) believe that it works 2) start by checking base case\n",
    "    3) prepare for giant case\n",
    "    \n",
    "    Summary of this function\n",
    "    1. Find best feature and threshold [question]\n",
    "    2. Split data on best feat and thres [quest]\n",
    "    3. recursively do 1 & 2 for split data\n",
    "    4. Return decision node with best feat and threshold, true branch and false branch\n",
    "    '''\n",
    "    \n",
    "    # find best question and return it's IV\n",
    "    gain, question = best_split(x) #This is 4th part which internally calls 1-3 part\n",
    "    \n",
    "    #base case when no split possible\n",
    "    # we can't split anymore so time for leaf node and store y distribution\n",
    "    if gain == 0:\n",
    "        return leaf(x)\n",
    "    \n",
    "    #we have best question so now time to split\n",
    "    #partition data on best question\n",
    "    true_rows, false_rows = partition_my_data(x,question) # part - 2\n",
    "    \n",
    "    #recursively build tree\n",
    "    true_branch = build_tree(true_rows)\n",
    "    \n",
    "    #recursively build tree\n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    return Decision_Node(question,true_branch,false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7th part - Print fitted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, sp = \"\"):\n",
    "    '''\n",
    "    print tree\n",
    "    '''\n",
    "    \n",
    "    #if it is a leaf, print y distribution\n",
    "    if isinstance(node, leaf):\n",
    "        print(sp,\"predict\",node.predictions)\n",
    "        return \n",
    "    \n",
    "    #question at node\n",
    "    print(sp,str(node.question))\n",
    "    \n",
    "    #print true branch recursively\n",
    "    print(sp,\"--> True\")\n",
    "    print_tree(node.true_branch,sp+\" \")\n",
    "    \n",
    "    #print true branch recursively\n",
    "    print(sp,\"--> False\")\n",
    "    print_tree(node.false_branch,sp+\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = build_tree(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is Sex_female == 0 \n",
      " --> True\n",
      "  is Pclass == 2 \n",
      "  --> True\n",
      "   is Parents/Children Aboard == 0 \n",
      "   --> True\n",
      "    is Siblings/Spouses Aboard == 0 \n",
      "    --> True\n",
      "     predict {1: 2, 0: 12}\n",
      "    --> False\n",
      "     predict {0: 4}\n",
      "   --> False\n",
      "    is Siblings/Spouses Aboard == 2 \n",
      "    --> True\n",
      "     predict {1: 1}\n",
      "    --> False\n",
      "     predict {1: 2, 0: 2}\n",
      "  --> False\n",
      "   is Siblings/Spouses Aboard == 0 \n",
      "   --> True\n",
      "    is Parents/Children Aboard == 2 \n",
      "    --> True\n",
      "     predict {0: 1, 1: 1}\n",
      "    --> False\n",
      "     is Pclass == 3 \n",
      "     --> True\n",
      "      is Parents/Children Aboard == 0 \n",
      "      --> True\n",
      "       predict {0: 47, 1: 6}\n",
      "      --> False\n",
      "       predict {0: 2}\n",
      "     --> False\n",
      "      is Parents/Children Aboard == 0 \n",
      "      --> True\n",
      "       predict {0: 11, 1: 3}\n",
      "      --> False\n",
      "       predict {0: 5, 1: 1}\n",
      "   --> False\n",
      "    is Siblings/Spouses Aboard == 1 \n",
      "    --> True\n",
      "     is Parents/Children Aboard == 1 \n",
      "     --> True\n",
      "      predict {1: 1, 0: 2}\n",
      "     --> False\n",
      "      is Pclass == 1 \n",
      "      --> True\n",
      "       predict {0: 5}\n",
      "      --> False\n",
      "       is Parents/Children Aboard == 0 \n",
      "       --> True\n",
      "        predict {0: 3, 1: 1}\n",
      "       --> False\n",
      "        predict {0: 3}\n",
      "    --> False\n",
      "     predict {0: 14}\n",
      " --> False\n",
      "  is Pclass == 3 \n",
      "  --> True\n",
      "   is Siblings/Spouses Aboard == 0 \n",
      "   --> True\n",
      "    is Parents/Children Aboard == 2 \n",
      "    --> True\n",
      "     predict {1: 2, 0: 1}\n",
      "    --> False\n",
      "     predict {1: 13, 0: 3}\n",
      "   --> False\n",
      "    is Siblings/Spouses Aboard == 1 \n",
      "    --> True\n",
      "     is Parents/Children Aboard == 1 \n",
      "     --> True\n",
      "      predict {1: 3}\n",
      "     --> False\n",
      "      is Parents/Children Aboard == 5 \n",
      "      --> True\n",
      "       predict {1: 1}\n",
      "      --> False\n",
      "       is Parents/Children Aboard == 0 \n",
      "       --> True\n",
      "        predict {0: 6, 1: 5}\n",
      "       --> False\n",
      "        predict {0: 1}\n",
      "    --> False\n",
      "     is Siblings/Spouses Aboard == 3 \n",
      "     --> True\n",
      "      is Parents/Children Aboard == 0 \n",
      "      --> True\n",
      "       predict {1: 1}\n",
      "      --> False\n",
      "       predict {0: 1}\n",
      "     --> False\n",
      "      is Siblings/Spouses Aboard == 4 \n",
      "      --> True\n",
      "       predict {1: 1, 0: 1}\n",
      "      --> False\n",
      "       predict {0: 4}\n",
      "  --> False\n",
      "   is Parents/Children Aboard == 0 \n",
      "   --> True\n",
      "    is Pclass == 1 \n",
      "    --> True\n",
      "     is Siblings/Spouses Aboard == 0 \n",
      "     --> True\n",
      "      predict {1: 4, 0: 1}\n",
      "     --> False\n",
      "      predict {1: 5}\n",
      "    --> False\n",
      "     is Siblings/Spouses Aboard == 0 \n",
      "     --> True\n",
      "      predict {1: 7, 0: 1}\n",
      "     --> False\n",
      "      predict {1: 3, 0: 1}\n",
      "   --> False\n",
      "    predict {1: 6}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9th part - classify new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_new_sample(sample,node):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    #when we have reached the leaf node\n",
    "    if isinstance(node,leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.question.match(sample):\n",
    "        return classify_new_sample(sample,node.true_branch)\n",
    "    \n",
    "    else:\n",
    "        return classify_new_sample(sample,node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = X.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 1}\n",
      "{1: 5}\n",
      "{1: 13, 0: 3}\n",
      "{1: 5}\n",
      "{0: 47, 1: 6}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(classify_new_sample(X.to_numpy()[i],my_tree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
